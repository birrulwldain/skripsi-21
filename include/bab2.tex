%-------------------------------------------------------------------------------
%                            BAB II
%               TINJAUAN PUSTAKA DAN DASAR TEORI
%-------------------------------------------------------------------------------

\chapter{TINJAUAN PUSTAKA}
\par Dalam bab ini, berbagai teori yang relevan dan literatur sebelumnya yang menunjang penelitian ini dibahas secara komprehensif. Pembahasan mencakup teknik spektroskopi yang diaplikasikan, metode analisis spektrum, serta penerapan teknik statistik dalam pemrosesan data spektroskopi dengan penekanan pada penerapan \textit{Deep Learning} di dalamnya. Arsitektur \textit{Long Short-Term Memory} (LSTM) diterapkan untuk memprediksi elemen dalam sampel tersebut.

\section{Spektroskopi Emisi Atom}
\subsection{Prinsip Dasar}
\label{subsec:prinsip-dasar}

Spektroskopi emisi atom bertumpu pada teori atom Bohr yang menjelaskan kuantisasi energi elektron melalui persamaan:
\begin{equation}
\label{eq:energi-bohr}
E_n = -\frac{13.6 \, \text{eV}}{n^2} \quad (n \in \mathbb{Z}^+),
\end{equation}
di mana transisi elektron antar tingkat energi memenuhi $\Delta E = h\nu$ \citep{Beiser1992}. Fenomena spektrum garis hidrogen mengikuti persamaan umum Rydberg:
\begin{equation}
\label{eq:rydberg-umum}
\frac{1}{\lambda} = R \left( \frac{1}{n_f^2} - \frac{1}{n_i^2} \right) \quad (n_i > n_f),
\end{equation}
dengan $R = 1.097 \times 10^7 \, \text{m}^{-1}$ sebagai konstanta Rydberg \citep{Beiser1992}. Contoh spesifik seperti deret Balmer ($n_f = 2$) dan Lyman ($n_f = 1$) menunjukkan konsistensi persamaan ini \citep{Griffiths2005}.

Mekanisme eksitasi terjadi ketika atom menyerap energi dari sumber eksternal (e.g., plasma), menyebabkan elektron berpindah ke tingkat energi lebih tinggi. De-eksitasi menghasilkan emisi foton dengan panjang gelombang:
\[
\lambda = \frac{hc}{\Delta E},
\]
di mana $h$ adalah konstanta Planck dan $c$ kecepatan cahaya. Aturan seleksi $\Delta l = \pm 1$ \citep{Liboff2003} membatasi transisi yang diperbolehkan, menghasilkan pola spektrum unik untuk setiap unsur.

Aplikasi praktis meliputi:
\begin{itemize}
\item Pemantauan polutan udara via spektroskopi laser resolusi tinggi \citep{Demtroder2010},
\item Analisis komposisi bintang menggunakan spektrograf astronomi \citep{Kaufmann2020},
\item Deteksi logam berat dengan teknik LIBS (\textit{Laser-Induced Breakdown Spectroscopy}).
\end{itemize}

Intensitas garis spektrum bergantung pada probabilitas transisi dan populasi elektron yang dapat dimodelkan dengan distribusi Boltzmann \citep{Demtroder2010}.
\subsubsection{Mekanisme eksitasi dan de-eksitasi atom.}
\subsubsection{Panjang gelombang emisi dan hubungannya dengan identifikasi unsur.}


\subsection{Hukum Beer-Lambert}

\subsubsection{Hukum Beer-Lambert dan aplikasinya dalam analisis kuantitatif.}
\subsubsection{Absorbansi, transmitansi, dan konsentrasi analit.}
\subsubsection{Keterbatasan Hukum Beer-Lambert.}


\subsection{Instrumentasi Spektroskopi Emisi}

\subsubsection{Sumber eksitasi (misalnya, plasma, api, arc).}
\subsubsection{Sistem dispersi cahaya (misalnya, prisma, kisi difraksi).}
\subsubsection{Detektor (misalnya, \textit{photomultiplier tube} (PMT), \textit{charge-coupled device} (CCD)).}
\subsubsection{Jenis-jenis spektrometer (misalnya, \textit{Czerny-Turner}, \textit{Echelle}) dan prinsip kerjanya.}


\section{Laser-Induced Breakdown Spectroscopy (LIBS)}

\subsection{Prinsip Dasar LIBS}

\subsubsection{Skema LIBS dan tahapan-tahapan dalam analisis LIBS.}
\subsubsection{Interaksi laser-materi: proses absorpsi energi dan peningkatan suhu.}
\subsubsection{Mekanisme ablasi laser: \textit{thermal vaporization}, \textit{photochemical decomposition}, \textit{photophysical sputtering}.}
\subsubsection{Formasi plasma: ionisasi atom dan molekul, pembentukan spesies tereksitasi.}
\subsubsection{Emisi atomik: de-eksitasi radiatif dan emisi foton pada panjang gelombang karakteristik.}

\subsubsection{Simulasi Spektrum Emisi:}

\par Penjelasan tentang bagaimana spektrum emisi dihasilkan dari plasma.
\par Persamaan intensitas emisi:  $I_{ij} = A_{ij} \cdot N_i \cdot h \cdot \nu_{ij}$,  dimana $I_{ij}$ adalah intensitas emisi, $A_{ij}$ adalah probabilitas transisi, $N_i$ adalah populasi atom pada tingkat energi i, $h$ adalah konstanta Planck, dan  $\nu_{ij}$ adalah frekuensi transisi.
\par Contoh simulasi spektrum emisi dengan Manim:


\subsubsection{Akuisisi dan analisis spektrum: identifikasi unsur dan kuantifikasi konsentrasi.}


\subsection{Karakteristik Plasma LIBS}

\subsubsection{Parameter plasma: suhu, densitas elektron, komposisi spesies.}
\subsubsection{Kesetimbangan Termodinamika Lokal (LTE): definisi dan kriteria pemenuhan.}
\subsubsection{Efek Stark: pergeseran dan pelebaran garis spektral akibat medan listrik dalam plasma.}
\subsubsection{Efek matriks: pengaruh komposisi sampel terhadap proses ablasi dan emisi.}


\subsection{Laser Nd:YAG dalam LIBS}

\subsubsection{Prinsip kerja laser Nd:YAG: media aktif, rongga resonator, proses \textit{pumping}.}
\subsubsection{Karakteristik laser Nd:YAG: panjang gelombang (1064 nm, 532 nm, 355 nm, 266 nm), energi pulsa, durasi pulsa (nanosecond, picosecond, femtosecond), mode operasi (\textit{Q-switched}, \textit{mode-locked}).}

\subsubsection{Diagram Grotrian Nd:YAG:}


\par Tingkat energi ion Nd$^{3+}$ dalam kristal YAG (4F$_{3/2}$, 4I$_{11/2}$, dll.).
\par Transisi elektronik yang menghasilkan emisi laser pada 1064 nm (4F$_{3/2}$ $\rightarrow$ 4I$_{11/2}$).
\par Mekanisme \textit{pumping} dan proses relaksasi non-radiatif.

\subsubsection{Keuntungan menggunakan laser Nd:YAG dalam LIBS: ketersediaan, keandalan, fleksibilitas panjang gelombang.}
\subsubsection{Pertimbangan dalam menggunakan laser Nd:YAG untuk CF-LIBS: validitas asumsi LTE.}


\subsection{Calibration-Free LIBS (CF-LIBS)}

\subsubsection{Motivasi CF-LIBS: mengatasi keterbatasan kalibrasi standar (efek matriks, kesulitan mendapatkan standar yang sesuai).}
\subsubsection{Prinsip dasar CF-LIBS: penggunaan persamaan Boltzmann dan Saha untuk menghubungkan intensitas emisi dengan konsentrasi unsur.}
\subsubsection{Metode CF-LIBS: \textit{one-line}, \textit{multi-line}, \textit{iterative}.}
\subsubsection{Asumsi LTE dalam CF-LIBS dan validitasnya pada plasma yang dihasilkan oleh laser Nd:YAG.}
\subsubsection{Keunggulan CF-LIBS: analisis kuantitatif tanpa standar, kecepatan, fleksibilitas.}
\subsubsection{Tantangan CF-LIBS: akurasi pengukuran parameter plasma, efek \textit{self-absorption}.}


\subsection{Aplikasi LIBS}

\subsubsection{Contoh aplikasi LIBS di berbagai bidang:}

\par Industri: kontrol kualitas, analisis logam dan paduan, identifikasi material.
\par Lingkungan: pemantauan polusi, analisis tanah dan air, karakterisasi limbah.
\par Kedokteran: analisis jaringan biologis, deteksi kanker, diagnosis penyakit.
\par Arkeologi: analisis artefak, identifikasi pigmen, penentuan asal-usul material.
\par Forensik: analisis material bukti, identifikasi bahan peledak, analisis \textit{gunshot residue}.
\section{Model Long Short-Term Memory (LSTM)}
\par Long Short-Term Memory (LSTM) adalah jenis jaringan saraf yang dirancang untuk mengatasi tantangan dalam memproses dan memprediksi urutan data. LSTM sangat efektif dalam menangkap dependensi jangka panjang dalam data sekuensial, yang membuatnya berguna dalam berbagai aplikasi, termasuk analisis deret waktu, pemrosesan bahasa alami, dan pengenalan suara. Dengan kemampuannya untuk mengingat informasi dalam jangka waktu yang lebih lama, LSTM telah menjadi alat penting dalam bidang pembelajaran mesin \citep{hochreiter1997}.
\par LSTM telah terbukti menjadi alat yang sangat efektif dalam berbagai aplikasi pembelajaran mesin. Dengan kemampuannya untuk menangkap dependensi jangka panjang dalam data sekuensial, LSTM telah membuka banyak peluang baru dalam analisis data dan pengembangan model prediktif. Meskipun ada tantangan yang perlu diatasi, potensi LSTM dalam berbagai bidang menjadikannya salah satu teknik yang paling menarik dalam pembelajaran mesin \citep{graves2013}.

\par Bagi para praktisi yang ingin mempelajari lebih lanjut tentang LSTM, disarankan untuk membaca literatur tambahan dan melakukan eksperimen dengan model. Menggunakan pustaka seperti Keras dapat mempermudah proses pengembangan dan pelatihan model. Selain itu, mengikuti perkembangan terbaru dalam penelitian LSTM dapat memberikan wawasan baru dan teknik yang lebih baik.

\section{Struktur dan Mekanisme LSTM}
\par Struktur LSTM terdiri dari beberapa komponen kunci, termasuk sel memori dan tiga pintu: pintu input, pintu lupa, dan pintu output. Pintu input mengontrol informasi baru yang masuk ke dalam sel memori, pintu lupa menentukan informasi mana yang harus dihapus, dan pintu output mengatur informasi yang akan dikeluarkan dari sel memori. Mekanisme ini memungkinkan LSTM untuk mempertahankan informasi yang relevan dan mengabaikan informasi yang tidak penting, sehingga meningkatkan kinerja model dalam memprediksi urutan data \citep{graves2013}.

\par Dalam analisis deret waktu, LSTM digunakan untuk memprediksi nilai masa depan berdasarkan data historis. Misalnya, dalam prediksi harga saham, model LSTM dapat dilatih menggunakan data harga historis untuk memprediksi harga di masa depan. Keunggulan LSTM dalam menangkap pola temporal membuatnya lebih unggul dibandingkan model tradisional, seperti regresi linier, yang sering kali gagal menangkap hubungan jangka panjang dalam data.

\section{Aplikasi LSTM}
\par LSTM juga banyak digunakan dalam pemrosesan bahasa alami (NLP), di mana urutan kata dalam kalimat sangat penting. Dalam tugas-tugas seperti penerjemahan bahasa dan analisis sentimen, LSTM dapat digunakan untuk memahami konteks dan makna dari urutan kata. Dengan memanfaatkan kemampuan LSTM untuk mengingat informasi dari kata-kata sebelumnya, model dapat menghasilkan terjemahan yang lebih akurat dan analisis sentimen yang lebih tepat \citep{zhang2019}.

\par Dalam pengenalan suara, LSTM digunakan untuk mengubah sinyal audio menjadi teks. Model ini dilatih menggunakan data audio yang telah dilabeli untuk mengenali pola dalam suara dan menghasilkan transkripsi yang akurat. Dengan kemampuan LSTM untuk menangkap informasi temporal, model dapat mengenali kata-kata dalam konteks yang lebih luas, meningkatkan akurasi pengenalan suara.

\section{Pelatihan dan Evaluasi Model LSTM}
\par Pelatihan model LSTM melibatkan penggunaan algoritma optimasi untuk meminimalkan fungsi kerugian. Proses ini biasanya dilakukan dengan menggunakan teknik backpropagation melalui waktu (BPTT), yang memungkinkan model untuk memperbarui bobot berdasarkan kesalahan prediksi. Pemilihan hyperparameter, seperti jumlah unit LSTM dan tingkat dropout, juga sangat penting untuk mencapai kinerja optimal \citep{bengio2012}.

\par Evaluasi model LSTM dilakukan dengan menggunakan metrik seperti akurasi, presisi, dan recall, tergantung pada jenis masalah yang dihadapi. Untuk masalah regresi, metrik seperti Mean Squared Error (MSE) sering digunakan. Evaluasi yang tepat sangat penting untuk memastikan bahwa model dapat diandalkan dan memberikan hasil yang akurat pada data baru.



\subsection{Input Layer}
\par Input layer adalah komponen pertama dalam arsitektur LSTM yang bertanggung jawab untuk menerima data masukan. Dalam konteks analisis spektrum, data yang dimasukkan biasanya berupa serangkaian nilai intensitas yang diukur pada berbagai panjang gelombang. Data ini perlu diubah menjadi format tiga dimensi, yaitu (samples, timesteps, features), agar dapat diproses oleh model LSTM. Misalnya, jika kita memiliki 1000 sampel, 10 timestep, dan 5 fitur, maka bentuk inputnya adalah:
$$
\text{Input Shape} = (1000, 10, 5)
$$
Pengaturan yang tepat dari input layer sangat penting untuk memastikan bahwa model dapat belajar dari data dengan efektif \cite{hochreiter1997}.

\par Selain itu, input layer juga berfungsi untuk menstandarisasi dan menormalisasi data sebelum diproses lebih lanjut. Proses ini penting untuk menghindari masalah yang dapat muncul akibat skala data yang berbeda, yang dapat mempengaruhi kinerja model. Normalisasi data dapat dilakukan dengan berbagai metode, seperti Min-Max Scaling atau Z-score Normalization. Dengan memastikan bahwa data berada dalam rentang yang sesuai, model dapat belajar dengan lebih cepat dan efisien, serta mengurangi risiko konvergensi yang lambat selama pelatihan.

\par Konfigurasi untuk input layer dalam kode Python menggunakan Keras dapat dituliskan sebagai berikut:
\begin{minipage}{\textwidth}
\begin{verbatim}
model.add(InputLayer(input_shape=(timesteps, features)))
\end{verbatim}
\end{minipage}

\subsection{LSTM Layer}
\par LSTM layer adalah inti dari model ini, yang dirancang untuk menangkap dependensi temporal dalam data sekuensial. Layer ini terdiri dari unit-unit LSTM yang memiliki kemampuan untuk menyimpan informasi dalam jangka waktu yang lebih lama dibandingkan dengan jaringan saraf tradisional. Setiap unit LSTM memiliki tiga pintu: pintu input, pintu lupa, dan pintu output, yang mengatur aliran informasi ke dalam dan keluar dari sel memori. Dengan mekanisme ini, LSTM dapat mengatasi masalah vanishing gradient yang sering terjadi pada jaringan saraf konvensional \cite{graves2013}.

\par Mekanisme pintu dalam LSTM memungkinkan model untuk memutuskan informasi mana yang harus disimpan dan mana yang harus dilupakan. Pintu input mengontrol informasi baru yang masuk ke dalam sel memori, pintu lupa menentukan informasi mana yang harus dihapus dari sel memori, dan pintu output mengatur informasi yang akan dikeluarkan dari sel memori. Dengan cara ini, LSTM dapat mempertahankan informasi yang relevan untuk jangka waktu yang lebih lama, sehingga sangat efektif dalam aplikasi yang memerlukan pemahaman konteks temporal, seperti analisis deret waktu dan pemrosesan bahasa alami.

\par Konfigurasi untuk LSTM layer dalam kode Python menggunakan Keras dapat dituliskan sebagai berikut:
\begin{minipage}{\textwidth}
\begin{verbatim}
model.add(LSTM(64, return_sequences=True, input_shape=(timesteps, features)))
\end{verbatim}
\end{minipage}

\subsection{Dropout Layer}
\par Dropout layer ditambahkan setelah LSTM layer untuk mengurangi risiko overfitting, yang merupakan masalah umum dalam pelatihan model dengan banyak parameter. Layer ini bekerja dengan cara mengabaikan sejumlah neuron secara acak selama proses pelatihan, sehingga model tidak terlalu bergantung pada neuron tertentu. Dengan demikian, dropout membantu meningkatkan generalisasi model terhadap data yang belum pernah dilihat sebelumnya \cite{bengio2012}.

\par Penentuan tingkat dropout yang tepat sangat penting untuk mencapai keseimbangan antara pelatihan yang efektif dan generalisasi yang baik. Biasanya, tingkat dropout berkisar antara 0.2 hingga 0.5, tergantung pada kompleksitas model dan ukuran dataset. Penelitian menunjukkan bahwa penggunaan dropout dapat secara signifikan meningkatkan akurasi model dalam berbagai aplikasi, termasuk analisis spektrum. Dengan mengurangi overfitting, model dapat memberikan prediksi yang lebih akurat dan dapat diandalkan ketika diterapkan pada data baru.

\par Konfigurasi untuk dropout layer dalam kode Python menggunakan Keras dapat dituliskan sebagai berikut:
\begin{minipage}{\textwidth}
\begin{verbatim}
model.add(Dropout(0.3))
\end{verbatim}
\end{minipage}

\subsection{Dense Layer}
\par Dense layer, atau fully connected layer, berfungsi untuk mengolah informasi yang diekstrak oleh LSTM layer dan menghasilkan output akhir dari model. Dalam konteks LSTM, dense layer biasanya digunakan setelah LSTM layer dan dropout layer. Layer ini menghubungkan setiap neuron di layer sebelumnya dengan setiap neuron di layer berikutnya, memungkinkan model untuk belajar dari kombinasi fitur yang lebih kompleks. Dengan cara ini, dense layer dapat menangkap interaksi yang lebih dalam antara fitur-fitur yang ada dalam data \cite{zhang2019}.

\par Fungsi aktivasi yang umum digunakan dalam dense layer adalah \texttt{ReLU} (Rectified Linear Unit) atau \texttt{tanh}. Pemilihan fungsi aktivasi yang tepat dapat mempengaruhi kinerja model secara signifikan. Setelah dense layer, biasanya terdapat satu output layer yang menghasilkan prediksi akhir, baik untuk regresi maupun klasifikasi. Dengan mengoptimalkan arsitektur dense layer, model dapat mencapai kinerja yang lebih baik dalam memprediksi hasil yang diinginkan, sehingga meningkatkan akurasi dan efisiensi dalam analisis data.

\par Konfigurasi untuk dense layer dalam kode Python menggunakan Keras dapat dituliskan sebagai berikut:
\begin{minipage}{\textwidth}
\begin{verbatim}
model.add(Dense(1024, activation='tanh'))
\end{verbatim}
\end{minipage}

\par Simulasi spektrum adalah alat penting dalam analisis spektroskopi, yang memungkinkan peneliti untuk memprediksi intensitas cahaya yang dipancarkan atau diserap oleh suatu substansi pada berbagai panjang gelombang. Kelas \texttt{SpectrumSimulator} dirancang untuk melakukan simulasi ini dengan mempertimbangkan berbagai parameter fisik, termasuk tingkat energi, degenerasi, dan koefisien Einstein.

\section{Struktur Kelas}
\par Kelas \texttt{SpectrumSimulator} memiliki beberapa atribut penting, termasuk \texttt{nist\_data}, \texttt{temperature}, dan \texttt{resolution}. Atribut \texttt{nist\_data} berisi data dari National Institute of Standards and Technology (NIST), yang mencakup informasi tentang tingkat energi dan koefisien transisi. Atribut \texttt{temperature} menentukan suhu dalam Kelvin, dan \texttt{resolution} mengatur resolusi spektrum yang dihasilkan.

\section{Metode Utama}
\par Kelas ini memiliki beberapa metode statis dan non-statis yang berfungsi untuk menghitung berbagai aspek dari simulasi spektrum:

\subsection{Fungsi Partisi}
\par Metode \texttt{partition\_function} menghitung fungsi partisi $$Z$$ berdasarkan tingkat energi dan degenerasi. Fungsi partisi adalah konsep penting dalam statistik termal yang digunakan untuk menghitung probabilitas distribusi keadaan dalam sistem termal. Fungsi ini didefinisikan sebagai:
$$
Z = \sum_{i} g_i e^{-\frac{E_i}{k_B T}}
$$
di mana $$g_i$$ adalah degenerasi, $$E_i$$ adalah tingkat energi, $$k_B$$ adalah konstanta Boltzmann, dan $$T$$ adalah suhu \citep{pathria2011}.

\subsection{Menghitung Intensitas}
\par Metode \texttt{calculate\_intensity} digunakan untuk menghitung intensitas spektrum berdasarkan suhu, energi, degenerasi, dan koefisien Einstein. Intensitas dapat dihitung dengan rumus:
$$
I = \frac{g \cdot e^{-\frac{E}{k_B T}} \cdot A}{Z}
$$
di mana $$I$$ adalah intensitas, $$g$$ adalah degenerasi, $$E$$ adalah energi, $$A$$ adalah koefisien Einstein, dan $$Z$$ adalah fungsi partisi \citep{mason2015}.


\section{Profil Voigt dalam Analisis Spektrum}
\par Profil Voigt adalah gabungan dari dua fungsi profil spektral: profil Lorentzian dan Gaussian. Fungsi Voigt sering digunakan untuk mendeskripsikan bentuk garis spektrum yang diukur dalam berbagai teknik spektroskopi, termasuk Laser Induced Breakdown Spectroscopy (LIBS). Fungsi Voigt dapat didefinisikan sebagai konvolusi dari fungsi Lorentzian dan Gaussian.

\subsection{Profil Lorentzian}
\par Fungsi Lorentzian, \( L(\lambda) \), menggambarkan lebar garis spektrum yang disebabkan oleh efek tekanan atau damping. Dalam konteks panjang gelombang \( \lambda \), fungsi Lorentzian dapat dinyatakan sebagai:
\begin{equation}
L(\lambda) = \frac{\Gamma / 2\pi}{(\lambda - \lambda_0)^2 + (\Gamma / 2)^2}
\end{equation}
di mana \( \lambda \) adalah panjang gelombang yang diukur, \( \lambda_0 \) adalah panjang gelombang pusat dari garis spektrum, dan \( \Gamma \) adalah lebar garis Lorentzian yang berhubungan dengan lebar dari garis spektrum akibat efek tekanan. Dalam hal ini, \( \Gamma \) adalah Full Width at Half Maximum (FWHM) dari profil Lorentzian.

\subsection{Profil Gaussian}
\par Fungsi Gaussian, \( G(\lambda) \), menggambarkan lebar garis spektrum yang disebabkan oleh efek Doppler, yang terkait dengan pergerakan relatif antara sumber spektrum dan detektor. Fungsi Gaussian dalam konteks panjang gelombang \( \lambda \) dinyatakan sebagai:

\begin{equation}
G(\lambda) = \frac{1}{\sqrt{2\pi \sigma^2}} \exp\left(-\frac{(\lambda - \lambda_0)^2}{2\sigma^2}\right)
\end{equation}
di mana \( \sigma \) adalah deviasi standar dari distribusi Gaussian, yang berkaitan dengan lebar dari garis spektrum dalam konteks efek Doppler. Deviasi standar \( \sigma \) berhubungan dengan Half Width at Half Maximum (HWHM) Gaussian, yang dinyatakan sebagai \( b = \sigma \sqrt{2 \ln 2} \).

\subsection{Konvolusi Gaussian dan Lorentzian}
\par Fungsi Voigt, \( V(\lambda; \Gamma, \sigma) \), adalah hasil konvolusi dari fungsi Lorentzian dan Gaussian. Konvolusi ini menghasilkan profil spektrum yang menggabungkan kedua efek. Fungsi Voigt didefinisikan sebagai:
\begin{equation}
V(\lambda; \Gamma, \sigma) = \int_{-\infty}^{\infty} G(\lambda - \lambda') L(\lambda') \, d\lambda'
\end{equation}
di mana \( \Gamma \) adalah lebar garis Lorentzian (FWHM), dan \( \sigma \) adalah deviasi standar Gaussian (HWHM).

\par Fungsi Voigt dapat disederhanakan dengan menggunakan fungsi \textit{W} (fungsi Voigt) yang merupakan integral konvolusi dari fungsi Lorentzian dan Gaussian. Fungsi Voigt dapat dinyatakan sebagai: \citep{Godio2016}
\begin{equation}
V(\lambda; a, b) = \text{Re} \left[ W\left(\frac{\lambda - \lambda_0 + i a}{b}\right) \right]
\end{equation}
di mana \( a \) adalah lebar Lorentzian (FWHM) dan \( b \) adalah deviasi standar Gaussian (HWHM). Fungsi Voigt kompleks, \( W(z) \), didefinisikan sebagai:
\begin{equation}
W(z) = e^{-z^2} \left( 1 + \text{erfi}(z) \right)
\end{equation}
dengan \text{erfi}(z) sebagai fungsi kesalahan kompleks.

\section{Simulasi Spektrum}
\par Metode \texttt{simulate} menggabungkan semua komponen di atas untuk menghasilkan spektrum. Metode ini pertama-tama menginisialisasi panjang gelombang dan intensitas, kemudian mengumpulkan tingkat energi dan degenerasi dari data NIST. Setelah menghitung fungsi partisi, intensitas dihitung untuk setiap transisi dan digabungkan menggunakan profil Gaussian. Hasil akhirnya adalah panjang gelombang dan intensitas yang dinormalisasi.

\par Kelas \texttt{SpectrumSimulator} menyediakan alat yang kuat untuk simulasi spektrum berdasarkan data fisik yang relevan. Dengan menggunakan metode statistik dan fisika dasar, kelas ini memungkinkan peneliti untuk memodelkan perilaku spektrum dengan akurasi yang tinggi. Simulasi ini dapat diterapkan dalam berbagai bidang, termasuk kimia, fisika, dan ilmu material.
